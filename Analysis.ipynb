{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "This notebook analyzes predicted results from the VM and attempt to do some other shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "\n",
    "from rouge import Rouge \n",
    "import util\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('saved_models', 'test', 'default-01-dev', 'X_batch.pk'), 'rb') as f:\n",
    "    X_batch = pickle.load(f)\n",
    "with open(os.path.join('saved_models', 'test', 'default-01-dev', 'logits_batch.pk'), 'rb') as f:\n",
    "    logits_batch = pickle.load(f)\n",
    "with open(os.path.join('saved_models', 'test', 'default-01-dev', 'gold_sums.pk'), 'rb') as f:\n",
    "    gold_sums = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15603/15603 [10:43<00:00, 16.40it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "with tqdm(total=sum(X.size(0) for X in X_batch)) as progress_bar:\n",
    "    for X, logits in zip(X_batch, logits_batch):\n",
    "        preds = util.tag_to_sents(X, logits, threshold=threshold, topk=0)\n",
    "        all_preds.extend(preds)\n",
    "        progress_bar.update(X.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496.56098186246237"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in all_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296.77952957764535"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in gold_sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = [i for i in range(len(all_preds)) \\\n",
    "        if len(all_preds[i]) > 0 and all_preds[i][0] != '.']\n",
    "pred = [all_preds[i] for i in valid_ids]\n",
    "ref = [gold_sums[i] for i in valid_ids]\n",
    "rouge = Rouge()\n",
    "results = rouge.get_scores(pred, ref, avg=True)\n",
    "results = {key: val['r'] for key, val in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': 0.5475826485350682,\n",
       " 'rouge-2': 0.2530427388975093,\n",
       " 'rouge-l': 0.5065710644392148}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"steve jobs was an . ceos of public companies are jobs was in from industries apple should invade to material used for the iphone ' s screen . jobs even got directly involved in customer service , was a part of apple ' s business for and . he fielded e - mails about broken laptops and intervened on support calls . by for at & t , apple ' s carrier partner for the iphone threatened a customer had twice e - mailed company ceo randall stephenson about price hikes with a cease - and - desist .\""
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"apple ' s steve jobs sometimes fielded customer service inquiries by e - mail . jobs sometimes provided exceptional support but could also be cold . ` ` i just wanted to apologize for your incredibly long wait , ' ' jobs told one customer .\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_sums[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15603/15603 [10:33<00:00, 16.82it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "with tqdm(total=sum(X.size(0) for X in X_batch)) as progress_bar:\n",
    "    for X, logits in zip(X_batch, logits_batch):\n",
    "        preds = util.tag_to_sents(X, logits, threshold=threshold, topk=0)\n",
    "        all_preds.extend(preds)\n",
    "        progress_bar.update(X.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357.61558674613855"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in all_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296.77952957764535"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in gold_sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = [i for i in range(len(all_preds)) \\\n",
    "        if len(all_preds[i]) > 0 and all_preds[i][0] != '.']\n",
    "pred = [all_preds[i] for i in valid_ids]\n",
    "ref = [gold_sums[i] for i in valid_ids]\n",
    "rouge = Rouge()\n",
    "results = rouge.get_scores(pred, ref, avg=True)\n",
    "results = {key: val['r'] for key, val in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': 0.45765437001340475,\n",
       " 'rouge-2': 0.19838525603185975,\n",
       " 'rouge-l': 0.4299853546278058}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15603/15603 [10:36<00:00, 16.17it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "with tqdm(total=sum(X.size(0) for X in X_batch)) as progress_bar:\n",
    "    for X, logits in zip(X_batch, logits_batch):\n",
    "        preds = util.tag_to_sents(X, logits, threshold=threshold, topk=0)\n",
    "        all_preds.extend(preds)\n",
    "        progress_bar.update(X.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.058193937063386"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in all_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296.77952957764535"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in gold_sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = [i for i in range(len(all_preds)) \\\n",
    "        if len(all_preds[i]) > 0 and all_preds[i][0] != '.']\n",
    "pred = [all_preds[i] for i in valid_ids]\n",
    "ref = [gold_sums[i] for i in valid_ids]\n",
    "rouge = Rouge()\n",
    "results = rouge.get_scores(pred, ref, avg=True)\n",
    "results = {key: val['r'] for key, val in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': 0.09553660816582144,\n",
       " 'rouge-2': 0.03769624998612457,\n",
       " 'rouge-l': 0.09203865068784273}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = []\n",
    "with tqdm(total=sum(X.size(0) for X in X_batch)) as progress_bar:\n",
    "    for X, logits in zip(X_batch, logits_batch):\n",
    "        preds = util.tag_to_sents(X, logits, threshold=threshold, topk=0)\n",
    "        all_preds.extend(preds)\n",
    "        progress_bar.update(X.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(sent) for sent in all_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([len(sent) for sent in gold_sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = [i for i in range(len(all_preds)) \\\n",
    "        if len(all_preds[i]) > 0 and all_preds[i][0] != '.']\n",
    "pred = [all_preds[i] for i in valid_ids]\n",
    "ref = [gold_sums[i] for i in valid_ids]\n",
    "rouge = Rouge()\n",
    "results = rouge.get_scores(pred, ref, avg=True)\n",
    "results = {key: val['r'] for key, val in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15603/15603 [10:39<00:00, 16.71it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "with tqdm(total=sum(X.size(0) for X in X_batch)) as progress_bar:\n",
    "    for X, logits in zip(X_batch, logits_batch):\n",
    "        preds = util.tag_to_sents(X, logits, threshold=threshold, topk=0)\n",
    "        all_preds.extend(preds)\n",
    "        progress_bar.update(X.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.763955649554573"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in all_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296.77952957764535"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in gold_sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = [i for i in range(len(all_preds)) \\\n",
    "        if len(all_preds[i]) > 0 and all_preds[i][0] != '.']\n",
    "pred = [all_preds[i] for i in valid_ids]\n",
    "ref = [gold_sums[i] for i in valid_ids]\n",
    "rouge = Rouge()\n",
    "results = rouge.get_scores(pred, ref, avg=True)\n",
    "results = {key: val['r'] for key, val in results.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': 0.02134545699922084,\n",
       " 'rouge-2': 0.009093250893266862,\n",
       " 'rouge-l': 0.020966324667971326}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights:\n",
    "\n",
    "1. Lower threshold results in longer sentences, and will trivially improve ROUGE scores. Thus we pick a threshold that match the predicted average length of the summaries with true average length of the summaries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEAD-3 Baseline\n",
    "\n",
    "We compare our results against a baseline result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
