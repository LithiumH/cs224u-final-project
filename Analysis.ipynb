{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "This notebook analyzes predicted results from the VM and attempt to do some other shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "\n",
    "from rouge import Rouge \n",
    "import util\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine = 'AWS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('saved_models', machine, 'test', 'default-01', 'X_batch.pk'), 'rb') as f:\n",
    "    X_batch = pickle.load(f)\n",
    "with open(os.path.join('saved_models', machine, 'test', 'default-01', 'logits_batch.pk'), 'rb') as f:\n",
    "    logits_batch = pickle.load(f)\n",
    "with open(os.path.join('saved_models', machine, 'test', 'default-01', 'gold_sums.pk'), 'rb') as f:\n",
    "    gold_sums = pickle.load(f)\n",
    "PROCESSED_DATA = os.path.join('data', 'data.pk')\n",
    "with open(PROCESSED_DATA, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEAD-3 Basline\n",
    "\n",
    "Here, we recover the source document by untokenizing from Bert and select the top 3 sentences as our \"summary\" and observe the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_normal_sent(lst_of_words):\n",
    "    return util.remove_bert_tokens(' '.join(lst_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "rouge = Rouge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['test']['X']\n",
    "gold_sums = data['test']['gold']\n",
    "recovered_X = [tokenizer.convert_ids_to_tokens(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lead_k(x, k=3, thresh=10):\n",
    "    start, look, i = 0, 0, 0\n",
    "    while i < k:\n",
    "        if '[SEP]' not in x[look:]:\n",
    "            start, look = 0, 100\n",
    "            break;\n",
    "        look = x.index('[SEP]', look)\n",
    "        look += 1\n",
    "        if look - start > thresh or i > 0:\n",
    "            i += 1\n",
    "        else:\n",
    "            start = look\n",
    "    look = min(look, 100)\n",
    "    return util.remove_bert_tokens(' '.join(x[start:look]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lead_3_sums = [lead_k(x, thresh=10) for x in recovered_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead-3 summaries avg length: 386.4782413638403\n",
      "gold summaries avg length: 296.30468499647503\n"
     ]
    }
   ],
   "source": [
    "print('lead-3 summaries avg length: {}'.format(np.mean([len(s) for s in lead_3_sums])))\n",
    "print('gold summaries avg length: {}'.format(np.mean([len(sent) for sent in gold_sums])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.3821599974324617,\n",
       "  'p': 0.34986469518907654,\n",
       "  'r': 0.44766975429590955},\n",
       " 'rouge-2': {'f': 0.15456418398646685,\n",
       "  'p': 0.138567864621563,\n",
       "  'r': 0.19059111347871827},\n",
       " 'rouge-l': {'f': 0.3238989896185224,\n",
       "  'p': 0.3155679251844099,\n",
       "  'r': 0.40387085568306264}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ids = [i for i in range(len(lead_3_sums)) \\\n",
    "        if len(lead_3_sums[i]) > 0 and lead_3_sums[i][0] != '.']\n",
    "lead_3_sums_filtered = [lead_3_sums[i] for i in valid_ids]\n",
    "gold_sums_filtered = [gold_sums[i] for i in valid_ids]\n",
    "rouge.get_scores(lead_3_sums_filtered, gold_sums_filtered, avg=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token tagging\n",
    "\n",
    "Here we explore some token taggnig ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range_dist(tup1, tup2):\n",
    "    \"\"\"\n",
    "    This function calculates the distance between 2 ranges.\n",
    "    \"\"\"\n",
    "    start1, end1 = min(tup1), max(tup1)\n",
    "    start2, end2 = min(tup2), max(tup2)\n",
    "    if start1 < start2 < end1 or start1 < end2 < end1: # overlap\n",
    "        return 0\n",
    "    return min(abs(end1 - start2), abs(end2 - start1))\n",
    "\n",
    "def tag(doc, tgt):\n",
    "    \"\"\"\n",
    "    doc: a list of src tokens\n",
    "    tgt: a list of tgt tokens that we will look for in the doc\n",
    "    \n",
    "    returns:\n",
    "    decode_label: a list of size tgt (or less) denoting the positions of the tokens at each summ step\n",
    "    \"\"\"\n",
    "    if len(tgt) == 0:\n",
    "        print('zero sized tgt')\n",
    "        return None\n",
    "\n",
    "    decode_label = []\n",
    "    l, r, last_range = 0, 0, (0, 0) # last step is the index into the src where we chose last\n",
    "    while r < len(tgt):\n",
    "        old_idxs = []\n",
    "        idxs = [(i,i+1) for i, token in enumerate(doc) if token == tgt[r]]\n",
    "        while len(idxs) > 0: # found a match\n",
    "            r += 1\n",
    "            old_idxs, idxs = idxs, []\n",
    "            for start, end in old_idxs:\n",
    "                if end < len(doc) and r < len(tgt) and doc[end] == tgt[r]:\n",
    "                    idxs.append((start, end + 1))\n",
    "        idx_to_look = old_idxs if len(idxs) == 0 else idxs\n",
    "        if len(idx_to_look) == 0:\n",
    "            r += 1\n",
    "        else:\n",
    "            best_i = min(range(len(idx_to_look)), key=lambda i: range_dist(last_range, idx_to_look[i]))\n",
    "            last_range = idx_to_look[best_i]\n",
    "            decode_label.extend(list(range(last_range[0], last_range[1])))\n",
    "    decode_label2 = []\n",
    "    l, r, last_range = 0, 0, (0, 0) # last step is the index into the src where we chose last\n",
    "    while r < len(tgt):\n",
    "        old_idxs = []\n",
    "        idxs = [(i,i+1) for i, token in enumerate(doc) if token == tgt[r]]\n",
    "        while len(idxs) > 0: # found a match\n",
    "            r += 1\n",
    "            old_idxs, idxs = idxs, []\n",
    "            for start, end in old_idxs:\n",
    "                if end < len(doc) and r < len(tgt) and doc[end] == tgt[r]:\n",
    "                    idxs.append((start, end + 1))\n",
    "        idx_to_look = old_idxs if len(idxs) == 0 else idxs\n",
    "        if len(idx_to_look) == 0:\n",
    "            r += 1\n",
    "        else:\n",
    "            best_i = 0\n",
    "            last_range = idx_to_look[best_i]\n",
    "            decode_label2.extend(list(range(last_range[0], last_range[1])))\n",
    "    return decode_label, decode_label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = tag(recovered_X[i], gold_sums[i].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\t57\t58\t62\t67\t68\t69\t146\t47\t46\t39\t82\t80\t81\t108\t83\t84\t85\t87\t89\t90\t91\t298\t299\t462\t463\t21\t22\t476\t189\t190\t179\t152\t153\t154\t155\t157\t437\t438\t490\t224\t433\t424\n"
     ]
    }
   ],
   "source": [
    "print('\\t'.join([str(elem) for elem in a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\t57\t58\t62\t67\t68\t69\t146\t47\t46\t39\t82\t80\t81\t108\t83\t84\t85\t9\t89\t90\t91\t298\t299\t18\t19\t21\t22\t476\t189\t190\t39\t152\t153\t154\t155\t71\t437\t438\t62\t167\t433\t39\n"
     ]
    }
   ],
   "source": [
    "print('\\t'.join([str(elem) for elem in b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"canadian security forces have thwarted an al - qaeda - backed terrorist plot to derail a new york city - bound passenger train as it crossed the niagara river , just a few miles from niagara falls . the royal canadian mounted police yesterday arrested chiheb esseghaier , 30 , of montreal , and raed jaser , 35 , of toronto . authorities allege the pair took orders and received guidance from al - qaeda operatives in iran . officials reportedly watched the men for more than a year and say the plot never got past the planning stages . canadian counter - terrorism investigators say the public was never in danger , the the men would have carried out the attack if they had not been stopped . police were later seen raiding jaser ' s house in northern toronto , carrying away material which could be used as evidence in the suspects ' prosecution . scroll down for video . raid : police were pictured at a house in toronto yesterday in connection with a plot to blow up a train . operation : the alleged would - be terrorists were under surveillance from canadian police for over a year . evidence : offers were pictured carrying away material from the home in the north of the city . neither of the men are canadian . citizens , but security officials would not reveal where they were from . or why they were in the country . the alleged plot is not believed to have any link with last week ' s boston marathon bombings . the two men allegedly planned to derail an amtrak or canadian via train . as it crossed over the whirpool rapids bridge from canada into the . united states , according to reports . the 115 - year - old arch bridge spans the niagara river 225 feet above the water . the canadian broadcasting corporation said the operations was conducted . with the u . s . department of homeland security and the fbi . thwarted : the raid came in the wake of the arrest of two foreigners living in canada with alleged al qaeda links . link : the house belongs to raed jaser , 32 , one of the two men arrested on monday . carried away : some of the material removed from the home by police as part of their investigation . a source told reuters that the amtrak maple leaf line , which runs from toronto to new york city , was targeted . canadian officials declined to confirm which trains were in the crosshairs . the men allegedly watched trains and rail yards across the greater toronto area to prepare for their assault . ` today ' s arrests\""
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_normal_sent(recovered_X[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"chiheb esseghaier , 30 , and raed jaser , 35 , were arrested yesterday . suspected received orders and got guidance from al qaeda leader in iran . planned to target new york - bound trains in toronto . jaser ' s house in toronto raided by police and evidence removed .\""
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_sums[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholds\n",
    "\n",
    "Here we change experiment with the thresholds and find a threshold that closely match the mean length of the gold summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15603/15603 [00:01<00:00, 11448.39it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "with tqdm(total=sum(X.size(0) for X in X_batch)) as progress_bar:\n",
    "    for X, logits in zip(X_batch, logits_batch):\n",
    "        preds = util.tag_to_sents(X, logits, threshold=threshold, topk=0)\n",
    "        all_preds.extend(preds)\n",
    "        progress_bar.update(X.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496.56098186246237"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in all_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296.77952957764535"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in gold_sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = [i for i in range(len(all_preds)) \\\n",
    "        if len(all_preds[i]) > 0 and all_preds[i][0] != '.']\n",
    "pred = [all_preds[i] for i in valid_ids]\n",
    "ref = [gold_sums[i] for i in valid_ids]\n",
    "# rouge = Rouge()\n",
    "# results = rouge.get_scores(pred, ref, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for the past year , he has been dubbed the ` most hated free man in america ' . now , george zimmerman ' s family have told of life following their relative ' s fatal shooting of trayvon martin in sanford , florida , in 2012 and acquittal last summer . it involves endless days of paranoia , safe house re - locations and get - rich - quick schemes , as as ` lots and lots ' of guns . it even features the use of a color - coded threat id system : code blue there is law enforcement at\""
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_preds[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'george zimmerman fatally shot trayvon martin in sanford , florida , in 2012 . he was acquitted of second - degree murder and manslaughter last summer . now , his family have opened up on their life following high - profile shooting . includes endless days of paranoia , safe house re - locations and lots of guns . they have even created a color - coded threat id system to warn of attacks . family are also battling financial issues , with zimmerman owing $ 2 . 5 million .'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_sums[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15603/15603 [00:01<00:00, 12702.92it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "with tqdm(total=sum(X.size(0) for X in X_batch)) as progress_bar:\n",
    "    for X, logits in zip(X_batch, logits_batch):\n",
    "        preds = util.tag_to_sents(X, logits, threshold=threshold, topk=0)\n",
    "        all_preds.extend(preds)\n",
    "        progress_bar.update(X.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "466.65192591168363"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in all_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296.77952957764535"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in gold_sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = [i for i in range(len(all_preds)) \\\n",
    "        if len(all_preds[i]) > 0 and all_preds[i][0] != '.']\n",
    "pred = [all_preds[i] for i in valid_ids]\n",
    "ref = [gold_sums[i] for i in valid_ids]\n",
    "rouge = Rouge()\n",
    "results = rouge.get_scores(pred, ref, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.4496899122869815,\n",
       "  'p': 0.40063215739225777,\n",
       "  'r': 0.53974616094343},\n",
       " 'rouge-2': {'f': 0.18567803647011386,\n",
       "  'p': 0.1559749627169229,\n",
       "  'r': 0.24639956474697608},\n",
       " 'rouge-l': {'f': 0.39346003244870503,\n",
       "  'p': 0.3737589285073313,\n",
       "  'r': 0.5040702011647212}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15603/15603 [00:01<00:00, 13316.56it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "with tqdm(total=sum(X.size(0) for X in X_batch)) as progress_bar:\n",
    "    for X, logits in zip(X_batch, logits_batch):\n",
    "        preds = util.tag_to_sents(X, logits, threshold=threshold, topk=0)\n",
    "        all_preds.extend(preds)\n",
    "        progress_bar.update(X.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427.02268794462606"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in all_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296.77952957764535"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in gold_sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = [i for i in range(len(all_preds)) \\\n",
    "        if len(all_preds[i]) > 0 and all_preds[i][0] != '.']\n",
    "pred = [all_preds[i] for i in valid_ids]\n",
    "ref = [gold_sums[i] for i in valid_ids]\n",
    "rouge = Rouge()\n",
    "results = rouge.get_scores(pred, ref, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.45086845580397156,\n",
       "  'p': 0.4185434317870088,\n",
       "  'r': 0.5168249621833642},\n",
       " 'rouge-2': {'f': 0.1829220373807808,\n",
       "  'p': 0.15901565244835605,\n",
       "  'r': 0.23124963445101152},\n",
       " 'rouge-l': {'f': 0.3999566875681731,\n",
       "  'p': 0.39202406330937495,\n",
       "  'r': 0.4843581547513276}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -1.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15603/15603 [00:01<00:00, 14216.06it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "with tqdm(total=sum(X.size(0) for X in X_batch)) as progress_bar:\n",
    "    for X, logits in zip(X_batch, logits_batch):\n",
    "        preds = util.tag_to_sents(X, logits, threshold=threshold, topk=0)\n",
    "        all_preds.extend(preds)\n",
    "        progress_bar.update(X.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363.1303595462411"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in all_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296.77952957764535"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in gold_sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = [i for i in range(len(all_preds)) \\\n",
    "        if len(all_preds[i]) > 0 and all_preds[i][0] != '.']\n",
    "pred = [all_preds[i] for i in valid_ids]\n",
    "ref = [gold_sums[i] for i in valid_ids]\n",
    "rouge = Rouge()\n",
    "results = rouge.get_scores(pred, ref, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'f': 0.44244367142312696,\n",
       "  'p': 0.44210512732771956,\n",
       "  'r': 0.47261537854014235},\n",
       " 'rouge-2': {'f': 0.17633962658940505,\n",
       "  'p': 0.16432195309989306,\n",
       "  'r': 0.2057540133100572},\n",
       " 'rouge-l': {'f': 0.39573376477645517,\n",
       "  'p': 0.4153099454535798,\n",
       "  'r': 0.44399267718797564}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"the obama administration launch the federal healthcare site was not ready to go live confidential report cnn . . the caution main contractor cgi warned of a of open risks and issues for healthcare . gov web site project . medicaid chief marilyn tavenner it website she not fore problems . ` ` tested website with ' . in ' ' . ' s . risks open says . is . c .\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"a confidential report obtained by cnn details warning that site was n ' t ready to go live . the main contractor warned of a number of open risks and issues for healthcare . gov . agency overseeing website said it addressed problems , was told project on track .\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15603/15603 [00:00<00:00, 26893.61it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "with tqdm(total=sum(X.size(0) for X in X_batch)) as progress_bar:\n",
    "    for X, logits in zip(X_batch, logits_batch):\n",
    "        preds = util.tag_to_sents(X, logits, threshold=threshold, topk=0)\n",
    "        all_preds.extend(preds)\n",
    "        progress_bar.update(X.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.3223098122156"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in all_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296.77952957764535"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(sent) for sent in gold_sums])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ids = [i for i in range(len(all_preds)) \\\n",
    "        if len(all_preds[i]) > 0 and all_preds[i][0] != '.']\n",
    "pred = [all_preds[i] for i in valid_ids]\n",
    "ref = [gold_sums[i] for i in valid_ids]\n",
    "# rouge = Rouge()\n",
    "# results = rouge.get_scores(pred, ref, avg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zimmerman martin . . id february , 2012 . he was acquitted murder and manslaughter . zimmerman .'"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'george zimmerman fatally shot trayvon martin in sanford , florida , in 2012 . he was acquitted of second - degree murder and manslaughter last summer . now , his family have opened up on their life following high - profile shooting . includes endless days of paranoia , safe house re - locations and lots of guns . they have even created a color - coded threat id system to warn of attacks . family are also battling financial issues , with zimmerman owing $ 2 . 5 million .'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref[12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights:\n",
    "\n",
    "1. Lower threshold results in longer sentences, and will trivially improve ROUGE scores. Thus we pick a threshold that match the predicted average length of the summaries with true average length of the summaries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold plots\n",
    "\n",
    "Simple thresholds is not gonna cut it. Must use plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test!\n",
    "\n",
    "After finding the best threshold, we use it on our test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine = 'Google'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('saved_models', machine, 'test', 'default-02', 'X_batch.pk'), 'rb') as f:\n",
    "    X_batch = pickle.load(f)\n",
    "with open(os.path.join('saved_models', machine, 'test', 'default-02', 'logits_batch.pk'), 'rb') as f:\n",
    "    logits_batch = pickle.load(f)\n",
    "with open(os.path.join('saved_models', machine, 'test', 'default-02', 'gold_sums.pk'), 'rb') as f:\n",
    "    gold_sums = pickle.load(f)\n",
    "PROCESSED_DATA = os.path.join('data', 'data.pk')\n",
    "with open(PROCESSED_DATA, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15603/15603 [00:01<00:00, 12974.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted summary mean length: 424.8680381977825\n",
      "gold summary mean length: 296.30468499647503\n",
      "{'rouge-1': {'f': 0.4491941871098484, 'p': 0.41709269253658604, 'r': 0.5149598947741703}, 'rouge-2': {'f': 0.18215143343088216, 'p': 0.1582838456230488, 'r': 0.23063813984371204}, 'rouge-l': {'f': 0.39814281109452004, 'p': 0.390356131165759, 'r': 0.48219031239701976}}\n"
     ]
    }
   ],
   "source": [
    "threshold = -1.8\n",
    "all_preds = []\n",
    "with tqdm(total=sum(X.size(0) for X in X_batch)) as progress_bar:\n",
    "    for X, logits in zip(X_batch, logits_batch):\n",
    "        preds = util.tag_to_sents(X, logits, threshold=threshold, topk=0)\n",
    "        all_preds.extend(preds)\n",
    "        progress_bar.update(X.size(0))\n",
    "print(\"predicted summary mean length: {}\".format(np.mean([len(sent) for sent in all_preds])))\n",
    "print(\"gold summary mean length: {}\".format(np.mean([len(sent) for sent in gold_sums])))\n",
    "valid_ids = [i for i in range(len(all_preds)) \\\n",
    "        if len(all_preds[i]) > 0 and all_preds[i][0] != '.']\n",
    "pred = [all_preds[i] for i in valid_ids]\n",
    "ref = [gold_sums[i] for i in valid_ids]\n",
    "rouge = Rouge()\n",
    "results = rouge.get_scores(pred, ref, avg=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine = 'Google'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('saved_models', machine, 'test', 'default-02-test', 'X_batch.pk'), 'rb') as f:\n",
    "    X_batch = pickle.load(f)\n",
    "with open(os.path.join('saved_models', machine, 'test', 'default-02-test', 'logits_batch.pk'), 'rb') as f:\n",
    "    logits_batch = pickle.load(f)\n",
    "with open(os.path.join('saved_models', machine, 'test', 'default-02-test', 'gold_sums.pk'), 'rb') as f:\n",
    "    gold_sums = pickle.load(f)\n",
    "PROCESSED_DATA = os.path.join('data', 'data.pk')\n",
    "with open(PROCESSED_DATA, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15603/15603 [00:01<00:00, 13453.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted summary mean length: 417.5348971351663\n",
      "gold summary mean length: 296.30468499647503\n",
      "{'rouge-1': {'f': 0.4480336311767712, 'p': 0.41528993073096937, 'r': 0.5129980577739018}, 'rouge-2': {'f': 0.18570456548816291, 'p': 0.16359561178490742, 'r': 0.23016669270617462}, 'rouge-l': {'f': 0.3970638920445901, 'p': 0.3878898983176103, 'r': 0.4793561493933291}}\n"
     ]
    }
   ],
   "source": [
    "threshold = -1.7\n",
    "all_preds = []\n",
    "with tqdm(total=sum(X.size(0) for X in X_batch)) as progress_bar:\n",
    "    for X, logits in zip(X_batch, logits_batch):\n",
    "        preds = util.tag_to_sents(X, logits, threshold=threshold, topk=0)\n",
    "        all_preds.extend(preds)\n",
    "        progress_bar.update(X.size(0))\n",
    "print(\"predicted summary mean length: {}\".format(np.mean([len(sent) for sent in all_preds])))\n",
    "print(\"gold summary mean length: {}\".format(np.mean([len(sent) for sent in gold_sums])))\n",
    "valid_ids = [i for i in range(len(all_preds)) \\\n",
    "        if len(all_preds[i]) > 0 and all_preds[i][0] != '.']\n",
    "pred = [all_preds[i] for i in valid_ids]\n",
    "ref = [gold_sums[i] for i in valid_ids]\n",
    "rouge = Rouge()\n",
    "results = rouge.get_scores(pred, ref, avg=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold as a detail extractor\n",
    "\n",
    "Varying thresholds can seen as be a way to achieve different level of abstraction. We also see a tradeoff between precision and recall, with higher thresholds increase precision while lower thresholds increase recall. It is not surprising since higher thresholds means a smaller predicted setence, and thus less tokens are being selected, but those who made it are much more likely to be in the target gold summary. Lower thresholds means a longer predicted sentence, and thus more tokens are selected, but it also tends to include non-essential words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = -0.5 # works pretty well in keyword/headline generation\n",
    "threshold = -1.7 # maximizes f-1 score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
