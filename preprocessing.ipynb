{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Key Phrase Extractor\n",
    "\n",
    "In this notebook we aim to realize the Bottom-Up Summarization Paper's extractor with BERT as the contextual embedding and see if we are able to extract phrases that maximizes the ROGUE scores. Our first goal in this project is to generate non-sensical summaries that maximizes the ROGUE score. Then, we aim to train an additional language model-like network to generate abstractive summaries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import json\n",
    "import pickle\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from rouge import Rouge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_STORY_DIR = os.path.join('data', 'cnn', 'stories')\n",
    "DM_STORY_DIR = os.path.join('data', 'dailymail', 'stories')\n",
    "\n",
    "CNN_STORY_TOKENIZED = os.path.join('data', 'cnn', 'stories-tokenized')\n",
    "DM_STORY_TOKENIZED = os.path.join('data', 'dailymail', 'stories-tokenized')\n",
    "\n",
    "SRC_JSON = os.path.join('data', 'src.pk')\n",
    "TGT_JSON = os.path.join('data', 'tgt.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCS = os.path.join('data', 'docs.pk')\n",
    "TAGS = os.path.join('data', 'tags.pk')\n",
    "IDX_TAGS = os.path.join('data', 'idx_tags.pk')\n",
    "IDS = os.path.join('data', 'idx.pk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "We will first read in the files and process them into tokenized sentences and words, and separate out the source document and the abstract. Here, we heavily borrowed code from Pointer Generator code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = [d for d in os.listdir(CNN_STORY_TOKENIZED)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm_single_close_quote = u'\\u2019' # unicode\n",
    "dm_double_close_quote = u'\\u201d'\n",
    "END_TOKENS = ['.', '!', '?', '...', \"'\", \"`\", '\"', dm_single_close_quote, dm_double_close_quote, \")\"] # acceptable ways to end a sentence\n",
    "SENTENCE_START = '<s>'\n",
    "SENTENCE_END = '</s>'\n",
    "def process_json(filename):\n",
    "    src, tgt = [], [] # a document is a list of list of words\n",
    "    highlight = False # highlights are always at the end of the document \n",
    "    f = open(filename, 'r')\n",
    "    parsed = json.load(f)\n",
    "    for sent in parsed['sentences']:\n",
    "        words = [word['word'] for word in sent['tokens']]\n",
    "        if words[-1] not in END_TOKENS:\n",
    "            words += ['.']\n",
    "        if words[0] == '@highlight':\n",
    "            highlight = True\n",
    "        elif highlight:\n",
    "            tgt += [words]\n",
    "        else:\n",
    "            src += [words]\n",
    "    return src, tgt\n",
    "\n",
    "src, tgt = process_json(os.path.join(CNN_STORY_TOKENIZED, dirs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_in_src_vocab(src, tgt):\n",
    "    src_vocab = set()\n",
    "    for sent in src:\n",
    "        src_vocab |= set(sent)\n",
    "    count = 0\n",
    "    total_len = 0\n",
    "    for sent in tgt:\n",
    "        for word in sent:\n",
    "            if word in src_vocab:\n",
    "                count += 1\n",
    "            total_len += 1\n",
    "    return count / total_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_json(file_dir):\n",
    "    pool = Pool(processes=10)\n",
    "    srcs, tgts = [], []\n",
    "    percentages = []\n",
    "    file_paths = [os.path.join(file_dir, file_name) for file_name in os.listdir(file_dir)]\n",
    "    for tup in pool.imap_unordered(process_json, file_paths):\n",
    "        src, tgt = tup\n",
    "        srcs.append(src)\n",
    "        tgts.append(tgt)\n",
    "        percentages.append(percentage_in_src_vocab(src, tgt))\n",
    "    print(np.mean(percentages))\n",
    "    return srcs, tgts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs_cnn, tgts_cnn = process_all_json(CNN_STORY_TOKENIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs_dm, tgts_dm = process_all_json(DM_STORY_TOKENIZED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, tgt = srcs_cnn + srcs_dm, tgts_cnn + tgts_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(SRC_JSON, 'wb')\n",
    "pickle.dump(src, f)\n",
    "f.close()\n",
    "\n",
    "f = open(TGT_JSON, 'wb')\n",
    "pickle.dump(tgt, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(SRC_JSON, 'rb')\n",
    "src = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open(TGT_JSON, 'rb')\n",
    "tgt = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess to BERT\n",
    "\n",
    "To use BERT, we must format our data into one that BERT is able to use. We also have to redefine the problem as a sequence tagging problem presented in the Bottom-Up paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', max_len=510)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(doc, tgt):\n",
    "    \"\"\"\n",
    "    doc: a list of src tokens\n",
    "    tgt: a list of tgt tokens that we will look for in the doc\n",
    "    \"\"\"\n",
    "    if len(tgt) == 0:\n",
    "        print('zero sized tgt')\n",
    "        return None\n",
    "    vocab = set(tgt)\n",
    "    doc = np.array(doc)\n",
    "    tgt = np.array(tgt)\n",
    "\n",
    "    label = np.zeros(len(doc), dtype=bool)\n",
    "    ## The following tags all tokens present in both the source and target\n",
    "    for i in range(len(doc)):\n",
    "        if doc[i] in vocab:\n",
    "            label[i] = 1\n",
    "    ## The following does the max tagging thingy the original paper did\n",
    "#     l, r = 0, 0\n",
    "#     while r < len(tgt):\n",
    "#         old_idxs = []\n",
    "#         idxs = [(i,i+1) for i, token in enumerate(doc) if token == tgt[r]]\n",
    "#         while len(idxs) > 0 and r + 1 < len(tgt):\n",
    "#             r += 1\n",
    "#             old_idxs, idxs = idxs, []\n",
    "#             for idx in old_idxs:\n",
    "#                 if idx[-1] < len(doc) and doc[idx[-1]] == tgt[r]:\n",
    "#                     idxs.append((idx[0], idx[-1] + 1))\n",
    "#         if len(idxs) > 0: ## we ran out of tgt\n",
    "#             label[idxs[0][0]:idxs[0][-1]] = 1\n",
    "#             break\n",
    "#         elif len(old_idxs) > 0: ## we found longest seq\n",
    "#             label[old_idxs[0][0]:old_idxs[0][-1]] = 1\n",
    "#         else: ## this token does not exist\n",
    "#             r += 1\n",
    "    idxs = []\n",
    "    for i in range(len(tgt)):\n",
    "        idxs.append(np.argwhere(doc == tgt[i]).flatten())  \n",
    "    return label, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_src_tgt(srcs, tgts, start_idx=0, end_idx=-1):\n",
    "    assert len(srcs) == len(tgts)\n",
    "    docs, tags = [], []\n",
    "    tagged_sum, gold_sum_bert, gold_sum_idxs = [], [], []\n",
    "    ranges = []\n",
    "    rn = range(len(srcs)) if end_idx == -1 else range(start_idx, end_idx)\n",
    "    for i in rn:\n",
    "        ## process src\n",
    "        sents = [' '.join(sent) + ' [SEP]' for sent in srcs[i]]\n",
    "        doc = ' '.join(['[CLS]'] + sents)\n",
    "        doc = tokenizer.tokenize(doc)[:510]\n",
    "\n",
    "        ## process tgt\n",
    "        tgt = ' '.join([' '.join(sent) for sent in tgts[i]])\n",
    "        tgt = tokenizer.tokenize(tgt)[:110]\n",
    "        label, idxs = tag(doc, tgt)\n",
    "        \n",
    "        ## generate tagged_summary for oracle rouge\n",
    "        tagged = []\n",
    "        for idx in idxs:\n",
    "            doc = np.array(doc)\n",
    "            if len(doc[idx]) > 0:\n",
    "                tagged.append(doc[idx][0])\n",
    "\n",
    "        ## Add both to list\n",
    "        docs.append(tokenizer.convert_tokens_to_ids(doc))\n",
    "        tags.append(label)\n",
    "        tagged_sum.append((' '.join(tagged)).replace(' ##', ''))\n",
    "        gold_sum_bert.append(' '.join(tgt).replace(' ##', ''))\n",
    "        gold_sum_idxs.append(idxs)\n",
    "        ranges.append(i)\n",
    "    return docs, tags, tagged_sum, gold_sum_bert, np.array(gold_sum_idxs), ranges\n",
    "docs, tags, tagged_sum, gold_sum_bert, gold_sum_idxs, ranges = process_src_tgt(src, tgt, 9, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gold_sum_idxs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"new : dozens of protesters are detained , ria novosti reports . tens of thousands brave the bitter cold in moscow to call for fair elections . the mass protest follows one this month after parliamentary election results were announced . demonstrators want an investigation into this month ' s election results .\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[\"new : dozens of protesters are detained , ria novosti reports . tens of thousands brave the bitter cold in moscow to call for fair elections . the mass protest follows one this month after parliamentary election results were announced . demonstrators want an investigation into this month ' s election results .\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_sum_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"new : dozens of protesters detained , ria novosti . tens of thousands the cold in moscow to for fair elections . the mass protest follows one this month after parliamentary election results were announced . demonstrators an this month ' s election results .\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[\"new : dozens of protesters detained , ria novosti . tens of thousands the cold in moscow to for fair elections . the mass protest follows one this month after parliamentary election results were announced . demonstrators an this month ' s election results .\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ranges(args):\n",
    "    return process_src_tgt(src, tgt, args[0], args[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 35\n",
    "pool = Pool(n)\n",
    "k = len(src)//n\n",
    "result = pool.map(process_ranges, [(start * k, (start+1) * k) for start in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_strictly_increasing(nested_sequence):\n",
    "    counter = 0\n",
    "    for sequence in nested_sequence:\n",
    "        for i in sequence:\n",
    "            if i != counter:\n",
    "                return False\n",
    "            counter += 1\n",
    "    return True\n",
    "check_strictly_increasing([tup[-1] for tup in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "src, tgt = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(lst, valid_ids):\n",
    "    return [lst[i] for i in valid_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, tags, tagged_sums, gold_sums_bert, gold_sums_idxs, ids = [], [], [], [], [], []\n",
    "for a, b, c, d, e, f in result:\n",
    "    valid_ids = [i for i in range(len(a)) if len(c[i]) > 0 and len(d[i]) > 0]\n",
    "    docs.extend(clean(a, valid_ids))\n",
    "    tags.extend(clean(b, valid_ids))\n",
    "    tagged_sums.extend(clean(c, valid_ids))\n",
    "    gold_sums_bert.extend(clean(d, valid_ids))\n",
    "    gold_sums_idxs.extend(clean(e, valid_ids))\n",
    "    ids.extend(clean(f, valid_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj, fname in zip([docs, tags, gold_sums_idxs, ids], [DOCS, TAGS, IDX_TAGS, IDS]):\n",
    "    with open(fname, 'wb') as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge-1': {'f': 0.8811621861531733, 'p': 0.9932318101053599, 'r': 0.8002531077407594}, 'rouge-2': {'f': 0.763622203917866, 'p': 0.839669677462507, 'r': 0.7053849661328021}, 'rouge-l': {'f': 0.8550856135961422, 'p': 0.9932296123897465, 'r': 0.8002515370628336}}\n",
      "{'rouge-1': {'f': 0.8811621861531733, 'p': 0.9932318101053599, 'r': 0.8002531077407594}, 'rouge-2': {'f': 0.763622203917866, 'p': 0.839669677462507, 'r': 0.7053849661328021}, 'rouge-l': {'f': 0.8550856135961422, 'p': 0.9932296123897465, 'r': 0.8002515370628336}}\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(tagged_sums, gold_sums_bert, avg=True)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert Model\n",
    "\n",
    "We have calculated the \"oracle\" score above, and now we would like to fit a model that accurately predicts the tags defined above.\n",
    "\n",
    "Later, we might change how the tags are defined and see if we can achieve better results than \"first occurance tagging\"\n",
    "\n",
    "We will split 90/5/5 with a 5k tiny dataset selected from the train set for faster development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, tags, gold_sums_idxs, ids = [pickle.load(open(file_path, 'rb')) for file_path in [DOCS, TAGS, IDX_TAGS, IDS]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {'rouge-1': {'f': 0.8811621861531733, 'p': 0.9932318101053599, 'r': 0.8002531077407594}, 'rouge-2': {'f': 0.763622203917866, 'p': 0.839669677462507, 'r': 0.7053849661328021}, 'rouge-l': {'f': 0.8550856135961422, 'p': 0.9932296123897465, 'r': 0.8002515370628336}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA = os.path.join('data', 'data.pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev_test, y_tags_train, y_tags_dev_test, y_decode_train, y_decode_dev_test, ids_train, ids_dev_test = \\\n",
    "        train_test_split(docs, tags, gold_sums_idxs, ids, test_size=0.1)\n",
    "X_dev, X_test, y_tags_dev, y_tags_test, y_decode_dev, y_decode_test, ids_dev, ids_test =\\\n",
    "        train_test_split(X_dev_test, y_tags_dev_test, y_decode_dev_test, ids_dev_test, test_size=0.5)\n",
    "X_tiny, y_tags_tiny, y_decode_tiny, ids_tiny = \\\n",
    "        X_train[:5000], y_tags_train[:5000], y_decode_train[:5000], ids_train[:5000]\n",
    "processed = dict()\n",
    "processed['train'] = {'X':X_train, 'y_tag':y_tags_train, 'y_decode':y_decode_train,\n",
    "        'ids':ids_train}\n",
    "processed['dev'] = {'X':X_dev, 'y_tag':y_tags_dev, 'y_decode':y_decode_dev,\n",
    "        'ids':ids_dev}\n",
    "processed['test'] = {'X':X_test, 'y_tag':y_tags_test, 'y_decode':y_decode_test,\n",
    "        'ids':ids_test}\n",
    "processed['tiny'] = {'X':X_tiny, 'y_tag':y_tags_tiny, 'y_decode':y_decode_tiny,\n",
    "        'ids':ids_tiny}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROCESSED_DATA, 'wb') as f:\n",
    "    pickle.dump(processed, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PROCESSED_DATA, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens([X_tiny[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative model (Unused)\n",
    "\n",
    "To train a generative model, we need to process the Glove embeddings.\n",
    "\n",
    "NO MORE GLOVE!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE_START = '<s>'\n",
    "SENTENCE_END = '</s>'\n",
    "def build_vocab(srcs):\n",
    "    vocab = {SENTENCE_START, SENTENCE_END}\n",
    "    for src in srcs:\n",
    "        # src is a list of list of words\n",
    "        for sent in src:\n",
    "            vocab |= set([word.lower() for word in sent])\n",
    "    return {word:i for i, word in enumerate(vocab)}\n",
    "vocab = build_vocab(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_HOME = os.path.join('data', 'glove.840B.300d.txt')\n",
    "def glove2dict(src_filename, model_vocab):\n",
    "    \"\"\"GloVe Reader.\n",
    "    Parameters\n",
    "    ----------\n",
    "    src_filename : str\n",
    "        Full path to the GloVe file to be processed.\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mapping words to their GloVe vectors.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    with open(src_filename, 'r', newline=\"\") as f:\n",
    "        while True:\n",
    "            try:\n",
    "                line = next(f)\n",
    "                line = line.strip().split()\n",
    "                line[0] = line[0].lower()\n",
    "                if line[0] in model_vocab:\n",
    "                    data[line[0]] = np.array(line[1: ], dtype=np.float)\n",
    "            except StopIteration:\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                pass\n",
    "            except:\n",
    "                pass\n",
    "    return data\n",
    "glove = glove2dict(GLOVE_HOME, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vocab = {word:i for i, word in enumerate(glove.keys())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocab) - len(glove_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_vocab = set()\n",
    "for t in tgt:\n",
    "    for sent in t:\n",
    "        for word in sent:\n",
    "            word = word.lower()\n",
    "            if word not in vocab:\n",
    "                not_in_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_vocab = {i:word for word, i in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join([reverse_vocab[i] for i in gold_sum_idxs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
